{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "833d5fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be90dd",
   "metadata": {},
   "source": [
    "## Connecting to the cloud EC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7beba9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0e376767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the SSH client\n",
    "ssh = paramiko.SSHClient()\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ae630fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the EC2 instance\n",
    "private_key_path = \"C:/Users/sebou/Downloads/test_key.pem\"\n",
    "key = paramiko.RSAKey.from_private_key_file(private_key_path)\n",
    "ssh.connect(hostname=\"ec2-18-133-73-36.eu-west-2.compute.amazonaws.com\",\n",
    "            username=\"ec2-user\",\n",
    "            pkey=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1296628b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_2_sqoop_incremental_import.sh\n",
      "_3_sqoop_incremental_import.sh\n",
      "_4_sqoop_incremental_load.sh\n",
      "data.txt\n",
      "departments.csv\n",
      "employees.csv\n",
      "file1.txt\n",
      "incremental_load_2.sh\n",
      "incremental_load_3.sh\n",
      "incremental_load.sh\n",
      "mapper.py\n",
      "output\n",
      "part-m-00001_copy_1\n",
      "part-m-00003\n",
      "project_info_seb.java\n",
      "QueryResult.java\n",
      "reducer.py\n",
      "seb_table.java\n",
      "sqoop_import.sh\n",
      "sqoop_incremental_import.sh\n",
      "test_2.csv\n",
      "test.csv\n",
      "the_z_table.java\n",
      "thursday_table.java\n",
      "ze_table.java\n",
      "_z_incremental_load.sh\n",
      "zipcodes20.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_command = \"\"\"\n",
    "u seb;\n",
    "ls;\n",
    "\"\"\"\n",
    "# Execute a command (example: list directory contents)\n",
    "stdin, stdout, stderr = ssh.exec_command(my_command)\n",
    "print(stdout.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc185b1b",
   "metadata": {},
   "source": [
    "## Using Sqoop \n",
    "#### To import tables from Postgres to Hive (hdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "eda6ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Sqoop command \n",
    "sqoop_command = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "# Variables\n",
    "HOSTNAME='ec2-3-9-191-104.eu-west-2.compute.amazonaws.com'\n",
    "DBNAME='testdb'\n",
    "USERNAME='consultants'\n",
    "PASSWORD='WelcomeItc@2022'\n",
    "TABLE='the_z_table'\n",
    "TARGET_DIR='/tmp/USUK30/seb/hive/the_z_table/'\n",
    "\n",
    "# Fetch the maximum id value from Hive\n",
    "LAST_VALUE=$(beeline -u 'jdbc:hive2://ip-172-31-3-80.eu-west-2.compute.internal:10000/default;' --silent=true -e \"SELECT MAX(id) FROM the_z_table;\" | grep -o '[0-9]*' | tail -n 1)\n",
    "\n",
    "echo \"Last recorded ID: $LAST_VALUE\"\n",
    "echo \"Starting new import from ID greater than $LAST_VALUE\"\n",
    "\n",
    "# Perform the incremental Sqoop import\n",
    "sqoop import \\\n",
    "    --connect jdbc:postgresql://${HOSTNAME}:5432/${DBNAME} \\\n",
    "    --username ${USERNAME} \\\n",
    "    --password ${PASSWORD} \\\n",
    "    --table ${TABLE} \\\n",
    "    --incremental append \\\n",
    "    --check-column id \\\n",
    "    --last-value ${LAST_VALUE} \\\n",
    "    --target-dir ${TARGET_DIR} \\\n",
    "    --m 1 \\\n",
    "    --as-textfile\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "22df1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the Sqoop command\n",
    "stdin, stdout, stderr = ssh.exec_command(sqoop_command) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3f143679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDOUT: Last recorded ID: 56\n",
      "Starting new import from ID greater than 56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Check the command's output\n",
    "output = stdout.read().decode('utf-8') \n",
    "print(\"STDOUT:\", output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ae8a3791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDERR: SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/log4j-slf4j-impl-2.13.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "WARNING: Use \"yarn jar\" to launch YARN applications.\n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/log4j-slf4j-impl-2.13.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/log4j-slf4j-impl-2.13.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "24/02/23 05:28:01 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7.7.1.7.0-551\n",
      "24/02/23 05:28:01 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.\n",
      "24/02/23 05:28:02 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "24/02/23 05:28:02 INFO tool.CodeGenTool: Beginning code generation\n",
      "24/02/23 05:28:04 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM \"the_z_table\" AS t LIMIT 1\n",
      "24/02/23 05:28:04 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "warning: No SupportedSourceVersion annotation found on org.apache.hadoop.hdds.conf.ConfigFileGenerator, returning RELEASE_6.\n",
      "warning: Supported source version 'RELEASE_6' from annotation processor 'org.apache.hadoop.hdds.conf.ConfigFileGenerator' less than -source '1.8'\n",
      "2 warnings\n",
      "24/02/23 05:28:14 WARN orm.CompilationManager: Could not rename /tmp/sqoop-ec2-user/compile/a13050625be9a78d9d2be8717b0a96ed/the_z_table.java to /home/ec2-user/./the_z_table.java. Error: Destination '/home/ec2-user/./the_z_table.java' already exists\n",
      "24/02/23 05:28:14 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-ec2-user/compile/a13050625be9a78d9d2be8717b0a96ed/the_z_table.jar\n",
      "24/02/23 05:28:14 INFO tool.ImportTool: Maximal id query for free form incremental import: SELECT MAX(\"id\") FROM \"the_z_table\"\n",
      "24/02/23 05:28:14 INFO tool.ImportTool: Incremental import based on column \"id\"\n",
      "24/02/23 05:28:14 INFO tool.ImportTool: Lower bound value: 56\n",
      "24/02/23 05:28:14 INFO tool.ImportTool: Upper bound value: 60\n",
      "24/02/23 05:28:14 WARN manager.PostgresqlManager: It looks like you are importing from postgresql.\n",
      "24/02/23 05:28:14 WARN manager.PostgresqlManager: This transfer can be faster! Use the --direct\n",
      "24/02/23 05:28:14 WARN manager.PostgresqlManager: option to exercise a postgresql-specific fast path.\n",
      "24/02/23 05:28:15 INFO mapreduce.ImportJobBase: Beginning import of the_z_table\n",
      "24/02/23 05:28:15 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "24/02/23 05:28:19 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "24/02/23 05:28:20 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-3-80.eu-west-2.compute.internal/172.31.3.80:8032\n",
      "24/02/23 05:28:23 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/ec2-user/.staging/job_1707928903337_0278\n",
      "24/02/23 05:28:33 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "24/02/23 05:28:33 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "24/02/23 05:28:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1707928903337_0278\n",
      "24/02/23 05:28:34 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "24/02/23 05:28:35 INFO conf.Configuration: resource-types.xml not found\n",
      "24/02/23 05:28:35 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "24/02/23 05:28:35 INFO impl.YarnClientImpl: Submitted application application_1707928903337_0278\n",
      "24/02/23 05:28:36 INFO mapreduce.Job: The url to track the job: http://ip-172-31-3-80.eu-west-2.compute.internal:8088/proxy/application_1707928903337_0278/\n",
      "24/02/23 05:28:36 INFO mapreduce.Job: Running job: job_1707928903337_0278\n",
      "24/02/23 05:28:43 INFO mapreduce.Job: Job job_1707928903337_0278 running in uber mode : false\n",
      "24/02/23 05:28:43 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "24/02/23 05:29:06 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "24/02/23 05:29:07 INFO mapreduce.Job: Job job_1707928903337_0278 completed successfully\n",
      "24/02/23 05:29:07 INFO mapreduce.Job: Counters: 33\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=260140\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=85\n",
      "\t\tHDFS: Number of bytes written=67\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tOther local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=22135\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=22135\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=88540\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=181329920\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=4\n",
      "\t\tMap output records=4\n",
      "\t\tInput split bytes=85\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=440\n",
      "\t\tCPU time spent (ms)=7830\n",
      "\t\tPhysical memory (bytes) snapshot=319926272\n",
      "\t\tVirtual memory (bytes) snapshot=6636982272\n",
      "\t\tTotal committed heap usage (bytes)=308805632\n",
      "\t\tPeak Map Physical memory (bytes)=319926272\n",
      "\t\tPeak Map Virtual memory (bytes)=6636982272\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=67\n",
      "24/02/23 05:29:08 INFO mapreduce.ImportJobBase: Transferred 67 bytes in 48.1472 seconds (1.3916 bytes/sec)\n",
      "24/02/23 05:29:08 INFO mapreduce.ImportJobBase: Retrieved 4 records.\n",
      "24/02/23 05:29:08 INFO util.AppendUtils: Appending to directory the_z_table\n",
      "24/02/23 05:29:08 INFO util.AppendUtils: Using found partition 4\n",
      "24/02/23 05:29:08 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:\n",
      "24/02/23 05:29:08 INFO tool.ImportTool:  --incremental append\n",
      "24/02/23 05:29:08 INFO tool.ImportTool:   --check-column id\n",
      "24/02/23 05:29:08 INFO tool.ImportTool:   --last-value 60\n",
      "24/02/23 05:29:08 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for errors\n",
    "errors = stderr.read().decode('utf-8')\n",
    "if errors:\n",
    "    print(\"STDERR:\", errors) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26543f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "229c2028",
   "metadata": {},
   "source": [
    "### We go to Hive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1c4ad6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import hive\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5018ae7",
   "metadata": {},
   "source": [
    "- **We set a tunnel**\n",
    "go to the command prompt, then execute the following (adapt if needed)\n",
    "```\n",
    "ssh -i \"C:/Users/sebou/Downloads/test_key.pem\" -L 10000:ip-172-31-3-80.eu-west-2.compute.internal:10000 ec2-user@ec2-18-133-73-36.eu-west-2.compute.amazonaws.com -N\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "148acc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after tunnel \n",
    "from pyhive import hive\n",
    "# Establish connection to Hive through the SSH tunnel\n",
    "conn = hive.Connection(host='localhost', port=10000, username='hive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "48268940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress specific UserWarnings related to pandas read_sql\n",
    "warnings.filterwarnings('ignore', message='pandas only supports SQLAlchemy connectable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "43e51295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Hive!\n",
      "   the_z_table.id the_z_table.name  the_z_table.age\n",
      "0               1         John Doe               30\n",
      "1               2       Jane Smith               32\n",
      "2               3     Alex Johnson               25\n",
      "3               4     Maria Garcia               28\n",
      "4               5         Chen Wei               33\n",
      "5               6     Olivia Brown               29\n",
      "6               7      Liam Miller               31\n",
      "7               8      Emma Wilson               27\n",
      "8               9       Noah Davis               34\n",
      "9              10       Ava Taylor               26\n"
     ]
    }
   ],
   "source": [
    "# Try establishing the connection\n",
    "try:\n",
    "    print(\"Connected to Hive!\")\n",
    "    # Example query\n",
    "    query = \"SELECT * FROM the_z_table LIMIT 10\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    print(df)\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Hive: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b05fdbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM the_z_table \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0d6a4c1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql: SELECT * FROM the_z_table \nunexpected exception\nunable to rollback",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m           Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thrift\\transport\\TSocket.py:178\u001b[0m, in \u001b[0;36mTSocket.write\u001b[1;34m(self, buff)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     plus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39msend(buff)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTTransportException\u001b[0m            Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:2018\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2017\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2018\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyhive\\hive.py:480\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, operation, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(req)\n\u001b[1;32m--> 480\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mExecuteStatement(req)\n\u001b[0;32m    481\u001b[0m _check_status(response)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\TCLIService\\TCLIService.py:279\u001b[0m, in \u001b[0;36mClient.ExecuteStatement\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m - req\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_ExecuteStatement(req)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecv_ExecuteStatement()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\TCLIService\\TCLIService.py:288\u001b[0m, in \u001b[0;36mClient.send_ExecuteStatement\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oprot\u001b[38;5;241m.\u001b[39mwriteMessageEnd()\n\u001b[1;32m--> 288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oprot\u001b[38;5;241m.\u001b[39mtrans\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thrift_sasl\\__init__.py:143\u001b[0m, in \u001b[0;36mTSaslClientTransport.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flushPlain(buffer)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trans\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thrift_sasl\\__init__.py:166\u001b[0m, in \u001b[0;36mTSaslClientTransport._flushPlain\u001b[1;34m(self, buffer)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flushPlain\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer):\n\u001b[0;32m    158\u001b[0m   \u001b[38;5;66;03m# When we have QOP of auth, sasl.encode() will pass the input to the output\u001b[39;00m\n\u001b[0;32m    159\u001b[0m   \u001b[38;5;66;03m# but won't put a length header, so we have to do that.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    164\u001b[0m   \u001b[38;5;66;03m# Python turn out to be REALLY expensive, but it seems to do a pretty\u001b[39;00m\n\u001b[0;32m    165\u001b[0m   \u001b[38;5;66;03m# good job of managing string buffer operations without excessive copies\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trans\u001b[38;5;241m.\u001b[39mwrite(struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>I\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(buffer)) \u001b[38;5;241m+\u001b[39m buffer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\thrift\\transport\\TSocket.py:185\u001b[0m, in \u001b[0;36mTSocket.write\u001b[1;34m(self, buff)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TTransportException(message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, inner\u001b[38;5;241m=\u001b[39me)\n",
      "\u001b[1;31mTTransportException\u001b[0m: unexpected exception",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotSupportedError\u001b[0m              Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:2022\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2022\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mrollback()\n\u001b[0;32m   2023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inner_exc:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyhive\\hive.py:358\u001b[0m, in \u001b[0;36mConnection.rollback\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrollback\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotSupportedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHive does not have transactions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotSupportedError\u001b[0m: Hive does not have transactions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[179], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(query, conn)\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:564\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    561\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[0;32m    565\u001b[0m         sql,\n\u001b[0;32m    566\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m    567\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    568\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[0;32m    569\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m    570\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    571\u001b[0m     )\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    574\u001b[0m     _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:2078\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2067\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2068\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2074\u001b[0m     dtype: DtypeArg \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2075\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m   2077\u001b[0m     args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 2078\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   2079\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:2027\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m inner_exc:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   2024\u001b[0m     ex \u001b[38;5;241m=\u001b[39m DatabaseError(\n\u001b[0;32m   2025\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124munable to rollback\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2026\u001b[0m     )\n\u001b[1;32m-> 2027\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2029\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql: SELECT * FROM the_z_table \nunexpected exception\nunable to rollback"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9d908d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the_z_table.id</th>\n",
       "      <th>the_z_table.name</th>\n",
       "      <th>the_z_table.age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alex Johnson</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Maria Garcia</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chen Wei</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   the_z_table.id the_z_table.name  the_z_table.age\n",
       "0               1         John Doe               30\n",
       "1               2       Jane Smith               32\n",
       "2               3     Alex Johnson               25\n",
       "3               4     Maria Garcia               28\n",
       "4               5         Chen Wei               33"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e8484796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the_z_table.id</th>\n",
       "      <th>the_z_table.name</th>\n",
       "      <th>the_z_table.age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>52</td>\n",
       "      <td>aMarion Lembert</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>53</td>\n",
       "      <td>aAlexia Hanson</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>54</td>\n",
       "      <td>aMariam Ahnia</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>55</td>\n",
       "      <td>aChon Wong</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>56</td>\n",
       "      <td>aOliver Town</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    the_z_table.id the_z_table.name  the_z_table.age\n",
       "41              52  aMarion Lembert               34\n",
       "42              53   aAlexia Hanson               25\n",
       "43              54    aMariam Ahnia               28\n",
       "44              55       aChon Wong               33\n",
       "45              56     aOliver Town               29"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "712d07e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the_z_table.id</th>\n",
       "      <th>the_z_table.name</th>\n",
       "      <th>the_z_table.age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>56</td>\n",
       "      <td>aOliver Town</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>57</td>\n",
       "      <td>bTeny Zern</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>58</td>\n",
       "      <td>bLarz Pison</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>59</td>\n",
       "      <td>bNiu Gip</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>60</td>\n",
       "      <td>bNius Gips</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    the_z_table.id the_z_table.name  the_z_table.age\n",
       "45              56     aOliver Town               29\n",
       "46              57       bTeny Zern               23\n",
       "47              58      bLarz Pison               32\n",
       "48              59         bNiu Gip               28\n",
       "49              60       bNius Gips               28"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb0c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0255332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to close the connection when done\n",
    "# ssh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7c182b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243c763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9e420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af3f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1fbbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1e25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96123ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd0ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06070f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339758a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5907e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "ssh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979b53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a22a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyhive\n",
    "# if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43f99876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install thrift\n",
    "# if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9152e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyhive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1653ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install thrift_sasl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91810c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d7da702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import hive\n",
    "import subprocess\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e9e74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "hostname = 'ec2-3-9-191-104.eu-west-2.compute.amazonaws.com'\n",
    "dbname = 'testdb'\n",
    "username = 'consultants'\n",
    "# Assume PASSWORD is set as an environment variable for security reasons\n",
    "# password = os.environ.get(\"DB_PASSWORD\")\n",
    "password ='WelcomeItc@2022'\n",
    "table = 'the_z_table'\n",
    "target_dir = '/tmp/USUK30/seb/hive/the_z_table/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba933e",
   "metadata": {},
   "source": [
    "run on the command prompt :\n",
    "```\n",
    "ssh -i \"C:\\Users\\sebou\\Downloads\\test_key.pem\" -L 10000:ip-172-31-3-80.eu-west-2.compute.internal:10000 ec2-user@ec2-18-133-73-36.eu-west-2.compute.amazonaws.com -N\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86dc689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = hive.Connection(host='localhost', port=10000, username='hive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f60c5dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last recorded ID: 51\n"
     ]
    }
   ],
   "source": [
    "from pyhive import hive\n",
    "# Assuming the connection is already established as conn\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT MAX(id) FROM the_z_table\")\n",
    "last_recorded_id = cursor.fetchone()[0]\n",
    "print(f\"Last recorded ID: {last_recorded_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd18d4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='ssh -i \"C:/Users/sebou/Downloads/test_key.pem\" ec2-user@your-remote-host \"sqoop import --connect jdbc:postgresql://ec2-3-9-191-104.eu-west-2.compute.amazonaws.com:5432/testdb --username consultants --password WelcomeItc@2022 --table the_z_table --m 1 --target-dir /tmp/USUK30/seb/hive/the_z_table --as-textfile\"', returncode=255)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "command = 'ssh -i \"C:/Users/sebou/Downloads/test_key.pem\" ec2-user@your-remote-host \"sqoop import --connect jdbc:postgresql://ec2-3-9-191-104.eu-west-2.compute.amazonaws.com:5432/testdb --username consultants --password WelcomeItc@2022 --table the_z_table --m 1 --target-dir /tmp/USUK30/seb/hive/the_z_table --as-textfile\"'\n",
    "subprocess.run(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c9ed581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='ssh -i \"C:\\\\Users\\\\sebou\\\\Downloads\\\\test_key.pem\" ec2-user@ec2-18-133-73-36.eu-west-2.compute.amazonaws.com \"sqoop import --connect jdbc:postgresql://ec2-3-9-191-104.eu-west-2.compute.amazonaws.com:5432/testdb --username consultants --password WelcomeItc@2022 --table the_z_table --m 1 --target-dir /tmp/USUK30/seb/hive/the_z_table --as-textfile\"', returncode=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = 'ssh -i \"C:\\\\Users\\\\sebou\\\\Downloads\\\\test_key.pem\" ec2-user@ec2-18-133-73-36.eu-west-2.compute.amazonaws.com \"sqoop import --connect jdbc:postgresql://ec2-3-9-191-104.eu-west-2.compute.amazonaws.com:5432/testdb --username consultants --password WelcomeItc@2022 --table the_z_table --m 1 --target-dir /tmp/USUK30/seb/hive/the_z_table --as-textfile\"'\n",
    "subprocess.run(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e344e7bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 19\u001b[0m\n\u001b[0;32m      4\u001b[0m sqoop_cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqoop\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjdbc:postgresql://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhostname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:5432/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdbname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--as-textfile\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m ]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Execute the Sqoop command\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m subprocess\u001b[38;5;241m.\u001b[39mrun(sqoop_cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Prepare the Sqoop command\n",
    "sqoop_cmd = [\n",
    "    \"sqoop\", \"import\",\n",
    "    \"--connect\", f\"jdbc:postgresql://{hostname}:5432/{dbname}\",\n",
    "    \"--username\", username,\n",
    "    \"--password\", password,\n",
    "    \"--table\", table,\n",
    "    \"--incremental\", \"append\",\n",
    "    \"--check-column\", \"id\",\n",
    "    \"--last-value\", str(last_recorded_id),\n",
    "    \"--target-dir\", target_dir,\n",
    "    \"--m\", \"1\",\n",
    "    \"--as-textfile\"\n",
    "]\n",
    "\n",
    "# Execute the Sqoop command\n",
    "subprocess.run(sqoop_cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c744cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca02e7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last recorded ID: 51\n"
     ]
    }
   ],
   "source": [
    "# Fetch the last recorded ID from Hive\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(f\"SELECT MAX(id) FROM {table}\")\n",
    "last_value = cursor.fetchone()[0]\n",
    "print(f\"Last recorded ID: {last_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af71a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incremental Sqoop import command\n",
    "sqoop_command = f\"\"\"\n",
    "sqoop import \\\n",
    "    --connect jdbc:postgresql://{hostname}:5432/{dbname} \\\n",
    "    --username {username} \\\n",
    "    --password {password} \\\n",
    "    --table {table} \\\n",
    "    --incremental append \\\n",
    "    --check-column id \\\n",
    "    --last-value {last_value} \\\n",
    "    --target-dir {target_dir} \\\n",
    "    --m 1 \\\n",
    "    --as-textfile\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4e7a6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute Sqoop command\n",
    "process = subprocess.run(sqoop_command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print(process.stdout.decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09972e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
