{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "060e3c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c42d17",
   "metadata": {},
   "source": [
    "## Connecting to the cloud EC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5939a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6c0c011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the SSH client\n",
    "ssh = paramiko.SSHClient()\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "49f3ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the EC2 instance\n",
    "private_key_path = \"C:/Users/sebou/Downloads/test_key.pem\"\n",
    "key = paramiko.RSAKey.from_private_key_file(private_key_path)\n",
    "ssh.connect(hostname=\"ec2-18-133-73-36.eu-west-2.compute.amazonaws.com\",\n",
    "            username=\"ec2-user\",\n",
    "            pkey=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5c3625c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_2_sqoop_incremental_import.sh\n",
      "_3_sqoop_incremental_import.sh\n",
      "_4_sqoop_incremental_load.sh\n",
      "data.txt\n",
      "departments.csv\n",
      "employees.csv\n",
      "file1.txt\n",
      "incremental_load_2.sh\n",
      "incremental_load_3.sh\n",
      "incremental_load.sh\n",
      "keith_sq.java\n",
      "mapper.py\n",
      "output\n",
      "part-m-00001_copy_1\n",
      "part-m-00003\n",
      "project_info_seb.java\n",
      "QueryResult.java\n",
      "reducer.py\n",
      "seb_table.java\n",
      "sqoop_import.sh\n",
      "sqoop_incremental_import.sh\n",
      "test_2.csv\n",
      "test.csv\n",
      "the_z_table.java\n",
      "thursday_table.java\n",
      "ze_table.java\n",
      "_z_incremental_load.sh\n",
      "zipcodes20.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_command = \"\"\"\n",
    "u seb;\n",
    "ls;\n",
    "\"\"\"\n",
    "# Execute a command (example: list directory contents)\n",
    "stdin, stdout, stderr = ssh.exec_command(my_command)\n",
    "print(stdout.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a9112",
   "metadata": {},
   "source": [
    "## Using Sqoop \n",
    "#### To import tables from Postgres to Hive (hdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "449fe281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Sqoop command \n",
    "sqoop_command = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "# Variables\n",
    "HOSTNAME='ec2-3-9-191-104.eu-west-2.compute.amazonaws.com'\n",
    "DBNAME='testdb'\n",
    "USERNAME='consultants'\n",
    "PASSWORD='WelcomeItc@2022'\n",
    "TABLE='the_z_table'\n",
    "TARGET_DIR='/tmp/USUK30/seb/hive/the_z_table/'\n",
    "\n",
    "# Fetch the maximum id value from Hive\n",
    "LAST_VALUE=$(beeline -u 'jdbc:hive2://ip-172-31-3-80.eu-west-2.compute.internal:10000/default;' --silent=true -e \"SELECT MAX(id) FROM the_z_table;\" | grep -o '[0-9]*' | tail -n 1)\n",
    "\n",
    "echo \"Last recorded ID: $LAST_VALUE\"\n",
    "echo \"Starting new import from ID greater than $LAST_VALUE\"\n",
    "\n",
    "# Perform the incremental Sqoop import\n",
    "sqoop import \\\n",
    "    --connect jdbc:postgresql://${HOSTNAME}:5432/${DBNAME} \\\n",
    "    --username ${USERNAME} \\\n",
    "    --password ${PASSWORD} \\\n",
    "    --table ${TABLE} \\\n",
    "    --incremental append \\\n",
    "    --check-column id \\\n",
    "    --last-value ${LAST_VALUE} \\\n",
    "    --target-dir ${TARGET_DIR} \\\n",
    "    --m 1 \\\n",
    "    --as-textfile\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4023f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the Sqoop command\n",
    "stdin, stdout, stderr = ssh.exec_command(sqoop_command) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "824074df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDOUT: Last recorded ID: 56\n",
      "Starting new import from ID greater than 56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Check the command's output\n",
    "output = stdout.read().decode('utf-8') \n",
    "print(\"STDOUT:\", output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "432cb396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDERR: SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/log4j-slf4j-impl-2.13.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "WARNING: Use \"yarn jar\" to launch YARN applications.\n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/log4j-slf4j-impl-2.13.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-7.1.7-1.cdh7.1.7.p0.15945976/jars/log4j-slf4j-impl-2.13.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "24/02/23 05:28:01 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7.7.1.7.0-551\n",
      "24/02/23 05:28:01 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.\n",
      "24/02/23 05:28:02 INFO manager.SqlManager: Using default fetchSize of 1000\n",
      "24/02/23 05:28:02 INFO tool.CodeGenTool: Beginning code generation\n",
      "24/02/23 05:28:04 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM \"the_z_table\" AS t LIMIT 1\n",
      "24/02/23 05:28:04 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\n",
      "warning: No SupportedSourceVersion annotation found on org.apache.hadoop.hdds.conf.ConfigFileGenerator, returning RELEASE_6.\n",
      "warning: Supported source version 'RELEASE_6' from annotation processor 'org.apache.hadoop.hdds.conf.ConfigFileGenerator' less than -source '1.8'\n",
      "2 warnings\n",
      "24/02/23 05:28:14 WARN orm.CompilationManager: Could not rename /tmp/sqoop-ec2-user/compile/a13050625be9a78d9d2be8717b0a96ed/the_z_table.java to /home/ec2-user/./the_z_table.java. Error: Destination '/home/ec2-user/./the_z_table.java' already exists\n",
      "24/02/23 05:28:14 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-ec2-user/compile/a13050625be9a78d9d2be8717b0a96ed/the_z_table.jar\n",
      "24/02/23 05:28:14 INFO tool.ImportTool: Maximal id query for free form incremental import: SELECT MAX(\"id\") FROM \"the_z_table\"\n",
      "24/02/23 05:28:14 INFO tool.ImportTool: Incremental import based on column \"id\"\n",
      "24/02/23 05:28:14 INFO tool.ImportTool: Lower bound value: 56\n",
      "24/02/23 05:28:14 INFO tool.ImportTool: Upper bound value: 60\n",
      "24/02/23 05:28:14 WARN manager.PostgresqlManager: It looks like you are importing from postgresql.\n",
      "24/02/23 05:28:14 WARN manager.PostgresqlManager: This transfer can be faster! Use the --direct\n",
      "24/02/23 05:28:14 WARN manager.PostgresqlManager: option to exercise a postgresql-specific fast path.\n",
      "24/02/23 05:28:15 INFO mapreduce.ImportJobBase: Beginning import of the_z_table\n",
      "24/02/23 05:28:15 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar\n",
      "24/02/23 05:28:19 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "24/02/23 05:28:20 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-3-80.eu-west-2.compute.internal/172.31.3.80:8032\n",
      "24/02/23 05:28:23 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/ec2-user/.staging/job_1707928903337_0278\n",
      "24/02/23 05:28:33 INFO db.DBInputFormat: Using read commited transaction isolation\n",
      "24/02/23 05:28:33 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "24/02/23 05:28:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1707928903337_0278\n",
      "24/02/23 05:28:34 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "24/02/23 05:28:35 INFO conf.Configuration: resource-types.xml not found\n",
      "24/02/23 05:28:35 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "24/02/23 05:28:35 INFO impl.YarnClientImpl: Submitted application application_1707928903337_0278\n",
      "24/02/23 05:28:36 INFO mapreduce.Job: The url to track the job: http://ip-172-31-3-80.eu-west-2.compute.internal:8088/proxy/application_1707928903337_0278/\n",
      "24/02/23 05:28:36 INFO mapreduce.Job: Running job: job_1707928903337_0278\n",
      "24/02/23 05:28:43 INFO mapreduce.Job: Job job_1707928903337_0278 running in uber mode : false\n",
      "24/02/23 05:28:43 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "24/02/23 05:29:06 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "24/02/23 05:29:07 INFO mapreduce.Job: Job job_1707928903337_0278 completed successfully\n",
      "24/02/23 05:29:07 INFO mapreduce.Job: Counters: 33\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=0\n",
      "\t\tFILE: Number of bytes written=260140\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=85\n",
      "\t\tHDFS: Number of bytes written=67\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tOther local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=22135\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=0\n",
      "\t\tTotal time spent by all map tasks (ms)=22135\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=88540\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=181329920\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=4\n",
      "\t\tMap output records=4\n",
      "\t\tInput split bytes=85\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=440\n",
      "\t\tCPU time spent (ms)=7830\n",
      "\t\tPhysical memory (bytes) snapshot=319926272\n",
      "\t\tVirtual memory (bytes) snapshot=6636982272\n",
      "\t\tTotal committed heap usage (bytes)=308805632\n",
      "\t\tPeak Map Physical memory (bytes)=319926272\n",
      "\t\tPeak Map Virtual memory (bytes)=6636982272\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=67\n",
      "24/02/23 05:29:08 INFO mapreduce.ImportJobBase: Transferred 67 bytes in 48.1472 seconds (1.3916 bytes/sec)\n",
      "24/02/23 05:29:08 INFO mapreduce.ImportJobBase: Retrieved 4 records.\n",
      "24/02/23 05:29:08 INFO util.AppendUtils: Appending to directory the_z_table\n",
      "24/02/23 05:29:08 INFO util.AppendUtils: Using found partition 4\n",
      "24/02/23 05:29:08 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:\n",
      "24/02/23 05:29:08 INFO tool.ImportTool:  --incremental append\n",
      "24/02/23 05:29:08 INFO tool.ImportTool:   --check-column id\n",
      "24/02/23 05:29:08 INFO tool.ImportTool:   --last-value 60\n",
      "24/02/23 05:29:08 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for errors\n",
    "errors = stderr.read().decode('utf-8')\n",
    "if errors:\n",
    "    print(\"STDERR:\", errors) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035b9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e2f7ac0",
   "metadata": {},
   "source": [
    "### We go to Hive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eae61e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import hive\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c10ba",
   "metadata": {},
   "source": [
    "- **We set a tunnel**\n",
    "go to the command prompt, then execute the following (adapt if needed)\n",
    "```\n",
    "ssh -i \"C:/Users/sebou/Downloads/test_key.pem\" -L 10000:ip-172-31-3-80.eu-west-2.compute.internal:10000 ec2-user@ec2-18-133-73-36.eu-west-2.compute.amazonaws.com -N\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "770497bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after tunnel \n",
    "from pyhive import hive\n",
    "# Establish connection to Hive through the SSH tunnel\n",
    "conn = hive.Connection(host='localhost', port=10000, username='hive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "232217df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress specific UserWarnings related to pandas read_sql\n",
    "warnings.filterwarnings('ignore', message='pandas only supports SQLAlchemy connectable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b4ef29dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Hive!\n",
      "   the_z_table.id the_z_table.name  the_z_table.age\n",
      "0               1         John Doe               30\n",
      "1               2       Jane Smith               32\n",
      "2               3     Alex Johnson               25\n",
      "3               4     Maria Garcia               28\n",
      "4               5         Chen Wei               33\n",
      "5               6     Olivia Brown               29\n",
      "6               7      Liam Miller               31\n",
      "7               8      Emma Wilson               27\n",
      "8               9       Noah Davis               34\n",
      "9              10       Ava Taylor               26\n"
     ]
    }
   ],
   "source": [
    "# Try establishing the connection\n",
    "try:\n",
    "    print(\"Connected to Hive!\")\n",
    "    # Example query\n",
    "    query = \"SELECT * FROM the_z_table LIMIT 10\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    print(df)\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Hive: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f64bd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM the_z_table \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7eef3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f78be655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the_z_table.id</th>\n",
       "      <th>the_z_table.name</th>\n",
       "      <th>the_z_table.age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alex Johnson</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Maria Garcia</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chen Wei</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   the_z_table.id the_z_table.name  the_z_table.age\n",
       "0               1         John Doe               30\n",
       "1               2       Jane Smith               32\n",
       "2               3     Alex Johnson               25\n",
       "3               4     Maria Garcia               28\n",
       "4               5         Chen Wei               33"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2a95a334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the_z_table.id</th>\n",
       "      <th>the_z_table.name</th>\n",
       "      <th>the_z_table.age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>52</td>\n",
       "      <td>aMarion Lembert</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>53</td>\n",
       "      <td>aAlexia Hanson</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>54</td>\n",
       "      <td>aMariam Ahnia</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>55</td>\n",
       "      <td>aChon Wong</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>56</td>\n",
       "      <td>aOliver Town</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    the_z_table.id the_z_table.name  the_z_table.age\n",
       "41              52  aMarion Lembert               34\n",
       "42              53   aAlexia Hanson               25\n",
       "43              54    aMariam Ahnia               28\n",
       "44              55       aChon Wong               33\n",
       "45              56     aOliver Town               29"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6870ce3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the_z_table.id</th>\n",
       "      <th>the_z_table.name</th>\n",
       "      <th>the_z_table.age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>56</td>\n",
       "      <td>aOliver Town</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>57</td>\n",
       "      <td>bTeny Zern</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>58</td>\n",
       "      <td>bLarz Pison</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>59</td>\n",
       "      <td>bNiu Gip</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>60</td>\n",
       "      <td>bNius Gips</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    the_z_table.id the_z_table.name  the_z_table.age\n",
       "45              56     aOliver Town               29\n",
       "46              57       bTeny Zern               23\n",
       "47              58      bLarz Pison               32\n",
       "48              59         bNiu Gip               28\n",
       "49              60       bNius Gips               28"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99134e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd2e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to close the connection when done\n",
    "# ssh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1b996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b32af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b002fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc5ba1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88987655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3123f3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2ab04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77fd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63821ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f8f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9513b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "ssh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2f162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae9e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyhive\n",
    "# if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "817c985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install thrift\n",
    "# if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c6a4072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyhive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "027904ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install thrift_sasl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff3ea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07ac7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import hive\n",
    "import subprocess\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d401d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "hostname = 'ec2-3-9-191-104.eu-west-2.compute.amazonaws.com'\n",
    "dbname = 'testdb'\n",
    "username = 'consultants'\n",
    "# Assume PASSWORD is set as an environment variable for security reasons\n",
    "# password = os.environ.get(\"DB_PASSWORD\")\n",
    "password ='WelcomeItc@2022'\n",
    "table = 'the_z_table'\n",
    "target_dir = '/tmp/USUK30/seb/hive/the_z_table/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34627623",
   "metadata": {},
   "source": [
    "run on the command prompt :\n",
    "```\n",
    "ssh -i \"C:\\Users\\sebou\\Downloads\\test_key.pem\" -L 10000:ip-172-31-3-80.eu-west-2.compute.internal:10000 ec2-user@ec2-18-133-73-36.eu-west-2.compute.amazonaws.com -N\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c759dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = hive.Connection(host='localhost', port=10000, username='hive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd0db21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last recorded ID: 51\n"
     ]
    }
   ],
   "source": [
    "from pyhive import hive\n",
    "# Assuming the connection is already established as conn\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT MAX(id) FROM the_z_table\")\n",
    "last_recorded_id = cursor.fetchone()[0]\n",
    "print(f\"Last recorded ID: {last_recorded_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec9bc837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='ssh -i \"C:/Users/sebou/Downloads/test_key.pem\" ec2-user@your-remote-host \"sqoop import --connect jdbc:postgresql://ec2-3-9-191-104.eu-west-2.compute.amazonaws.com:5432/testdb --username consultants --password WelcomeItc@2022 --table the_z_table --m 1 --target-dir /tmp/USUK30/seb/hive/the_z_table --as-textfile\"', returncode=255)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "command = 'ssh -i \"C:/Users/sebou/Downloads/test_key.pem\" ec2-user@your-remote-host \"sqoop import --connect jdbc:postgresql://ec2-3-9-191-104.eu-west-2.compute.amazonaws.com:5432/testdb --username consultants --password WelcomeItc@2022 --table the_z_table --m 1 --target-dir /tmp/USUK30/seb/hive/the_z_table --as-textfile\"'\n",
    "subprocess.run(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73184162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='ssh -i \"C:\\\\Users\\\\sebou\\\\Downloads\\\\test_key.pem\" ec2-user@ec2-18-133-73-36.eu-west-2.compute.amazonaws.com \"sqoop import --connect jdbc:postgresql://ec2-3-9-191-104.eu-west-2.compute.amazonaws.com:5432/testdb --username consultants --password WelcomeItc@2022 --table the_z_table --m 1 --target-dir /tmp/USUK30/seb/hive/the_z_table --as-textfile\"', returncode=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = 'ssh -i \"C:\\\\Users\\\\sebou\\\\Downloads\\\\test_key.pem\" ec2-user@ec2-18-133-73-36.eu-west-2.compute.amazonaws.com \"sqoop import --connect jdbc:postgresql://ec2-3-9-191-104.eu-west-2.compute.amazonaws.com:5432/testdb --username consultants --password WelcomeItc@2022 --table the_z_table --m 1 --target-dir /tmp/USUK30/seb/hive/the_z_table --as-textfile\"'\n",
    "subprocess.run(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98b7b51f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 19\u001b[0m\n\u001b[0;32m      4\u001b[0m sqoop_cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqoop\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjdbc:postgresql://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhostname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:5432/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdbname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--as-textfile\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m ]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Execute the Sqoop command\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m subprocess\u001b[38;5;241m.\u001b[39mrun(sqoop_cmd, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Prepare the Sqoop command\n",
    "sqoop_cmd = [\n",
    "    \"sqoop\", \"import\",\n",
    "    \"--connect\", f\"jdbc:postgresql://{hostname}:5432/{dbname}\",\n",
    "    \"--username\", username,\n",
    "    \"--password\", password,\n",
    "    \"--table\", table,\n",
    "    \"--incremental\", \"append\",\n",
    "    \"--check-column\", \"id\",\n",
    "    \"--last-value\", str(last_recorded_id),\n",
    "    \"--target-dir\", target_dir,\n",
    "    \"--m\", \"1\",\n",
    "    \"--as-textfile\"\n",
    "]\n",
    "\n",
    "# Execute the Sqoop command\n",
    "subprocess.run(sqoop_cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f14671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7013ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last recorded ID: 51\n"
     ]
    }
   ],
   "source": [
    "# Fetch the last recorded ID from Hive\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(f\"SELECT MAX(id) FROM {table}\")\n",
    "last_value = cursor.fetchone()[0]\n",
    "print(f\"Last recorded ID: {last_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca470af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incremental Sqoop import command\n",
    "sqoop_command = f\"\"\"\n",
    "sqoop import \\\n",
    "    --connect jdbc:postgresql://{hostname}:5432/{dbname} \\\n",
    "    --username {username} \\\n",
    "    --password {password} \\\n",
    "    --table {table} \\\n",
    "    --incremental append \\\n",
    "    --check-column id \\\n",
    "    --last-value {last_value} \\\n",
    "    --target-dir {target_dir} \\\n",
    "    --m 1 \\\n",
    "    --as-textfile\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "add93868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute Sqoop command\n",
    "process = subprocess.run(sqoop_command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print(process.stdout.decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebfa93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
